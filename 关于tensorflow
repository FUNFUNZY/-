https://blog.csdn.net/zj360202/article/details/78647075

为了理解Tensorflow，我们首先要明确以下几点:

1.使用图 (graph) 来表示计算任务.
2.在被称之为 会话 (Session) 的上下文 (context) 中执行图.
3.使用 tensor 表示数据.
4.通过 变量 (Variable) 维护状态.

Tensorflow将计算与执行分离开来：
阶段1：创建一张图，定义好图中的就算
阶段2：使用session（会话）去执行图中的计算

tensor 看作是一个 n 维的数组或列表.

关于张量：
1.要了解张量首先了解一下向量：向量是有长度有方向的，可以表示速度、力等物理量，还可以表示平面（垂直于平面的法向量）

2.其次要了解 分量 (Components) 与基向量 (Basic Vectors）：
   在笛卡尔坐标系中，基向量用来描述长度的基本单位，长度为1，基向量方向即为坐标系方向；
    分量就是（2,3,4）<---- 基向量为x,y,z  2x+3y+4z
    
3.由于每个分量只有一个下标（每个分量只由一个基向量构成），向量也称为1阶张量（Tensors of rank 1）
标量（scalar）也称为0阶张量，（标量没有方向，不存在基向量），可以说标量的每个分量是由0个基向量构成的。

4.张量-->用基向量与分量组合表示物理量
张量所描述的物理量是不随观察者或者说参考系而变化的，当参考系变化时（其实就是基向量变化），
其分量也会相应变化，最后结果就是基向量与分量的组合（也就是张量）保持不变

假设有3维空间的三阶张量：这个张量有27个基向量与27个分量，
     每个分量有3个下标，所有的下标组合共有3*3*3=27个，故共有27组基向量，不同基向量对应一个分量



TensorFlow文档中使用了三种记号来方便地描述张量的维度：阶，形状以及维数.下表展示了他们之间的关系：

阶	形状	维数	实例
0	[ ]	0-D	一个 0维张量. 一个纯量.
1	[D0]	1-D	一个1维张量的形式[5].
2	[D0, D1]	2-D	一个2维张量的形式[3, 4].
3	[D0, D1, D2]	3-D	一个3维张量的形式 [1, 4, 3].
n	[D0, D1, ... Dn]	n-D	一个n维张量的形式 [D0, D1, ... Dn].


tensorflow 中的张量

阶	数学实例	Python 例子
0	纯量 (只有大小)	s = 483
1	向量(大小和方向)	v = [1.1, 2.2, 3.3]
2	矩阵(数据表)	m = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
3	3阶张量 (数据立体)	t = [[[2], [4], [6]], [[8], [10], [12]], [[14], [16], [18]]]
n	n阶 (自己想想看)	....





tensorflow提供了多种optimizer，典型梯度下降GradientDescent和Adagrad、Momentum、Nestrov、Adam等变种。

典型的学习步骤是梯度下降GradientDescent，optimizer可以自动实现这一过程，通过指定loss来串联所有相关变量形成计算图，
然后通过optimizer(learning_rate).minimize(loss)实现自动梯度下降。minimize()也是两步操作的合并，后边会分解。

optimizer=tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)


tf.nn模块的操作
https://blog.csdn.net/qq_36653505/article/details/81105894











































https://blog.csdn.net/huqinweI987/article/details/82771521


张量：https://www.zhihu.com/question/23720923/answer/32739132
     https://blog.csdn.net/hpulfc/java/article/details/80886117

查看 tf 2.0 symbols map
https://docs.google.com/spreadsheets/d/1FLFJLzg7WNP6JHODX5q8BDgptKafq_slHpnHVbJIteQ/edit#gid=0
