降维就是指采用某种映射方法，将原高维空间中的数据点映射到低维度的空间中。
降维的本质是学习一个映射函数 f : x->y，其中x是原始数据点的表达，目前最多使用向量表达形式。y是数据点映射后的低维向量表达，通常y的维度小于x的维度
（当然提高维度也是可以的）。f可能是显式的或隐式的、线性的或非线性的。

主成分分析算法（PCA）
(PCA)是最常用的线性降维方法，它的目标是通过某种线性投影，将高维的数据映射到低维的空间中表示，并期望在所投影的维度上数据的方差最大，
以此使用较少的数据维度，同时保留住较多的原数据点的特性。






分析高维数据过程中碰到最大的问题就是维数的膨胀，也就是通常所说的“维数灾难”问题
高维数据考虑：1.数据会变稀疏 2.过拟合 3.高维空间不易预测 4.需要更多的样本

数据降维解决数据灾难
1.主成分分析PCA
通过原变量的线性组合得到一组新的综合变量，新的综合变量称主成分。主成分含有原变量的绝大部分信息，所以可以用这几个成分来代替原变量，从而实现数据降维。
但，主成分分析只在数据空间维度远小于样本量的条件适用，在数据空间维度很高的情况，不适用。引入了Lasso回归。

2. Lasso 回归



降维的作用：（为什么会有这些作用？） 
（1）降低时间的复杂度和空间复杂度 
（2）节省了提取不必要特征的开销 
（3）去掉数据集中夹杂的噪音 
（4）较简单的模型在小数据集上有更强的鲁棒性 
（5）当数据能有较少的特征进行解释，我们可以更好地解释数据，是的我们可以提取知识 
（6）实现数据的可视化 

降维的目的： 用来进行特征选择和特征提取。 
①特征选择：选择重要的特征子集，删除其余特征； 
②特征提取：由原始特征形成的较少的新特征。 
在特征提取中，我们要找到k个新的维度的集合，这些维度是原来k个维度的组合，这个方法可以是监督的，也可以是非监督的，如PCA是非监督的，LDA是监督的。 


https://blog.csdn.net/weixin_41988628/article/details/83214327
