神經網絡的訓練可以分為兩個步驟：一個是前向傳播，另外一個是反向傳播。

神經網絡就是通過不斷的前向傳播和反向傳播不斷調整神經網絡的權重，最終到達預設的疊代次數或者對樣本的學習已經到了比較好的程度後，就停止疊代，
那麼一個神經網絡就訓練好了。

前向傳播就是從輸入層開始（Layer1），經過一層層的Layer，不斷計算每一層的z和a，最後得到輸出y^的過程。

我們可以將神經網絡分解為許多個神經元，每個神經元接收上一層的輸入進行簡單的邏輯回歸操作，全部神經元從輸入層開始到輸出層依次進行邏輯回歸的過程我們
可以簡單的理解為神經網絡的前向傳播。

前向傳播是從神經網絡的輸入層開始，逐漸往輸出層進行前向傳播，上一層的神經元與本層的神經元有連接，那麼本層的神經元的激活等於上一層神經元對應的權值
進行加權和運算，最後通過一個非線性函數（激活函數）如ReLu，sigmoid等函數，最後得到的結果就是本層神經元的輸出。神經網絡逐層逐神經元通過該操作向前傳播，
最終得到輸出層的結果。



原文網址：https://kknews.cc/code/p9jkxlj.html


[Deep Learning] 神经网络基础：https://www.cnblogs.com/maybe2030/p/5597716.html（这篇文章写得太棒啦！！）

感知机模型可以由如下公式表示：y=f(wx+b)
我们日常生活中很多问题，甚至说大多数问题都不是线性可分问题，那我们要解决非线性可分问题该怎样处理呢？
既然单层感知机解决不了非线性问题，那我们就采用多层感知机事实上，感知机是一种判别式的线性分类模型，可以解决与、或、非这样的简单的线性可分（linearly separable）问题，
常将多层感知机这样的多层结构称之为是神经网络

误差逆传播算法（— BP学习算法——）
　所谓神经网络的训练或者是学习，其主要目的在于通过学习算法得到神经网络解决指定问题所需的参数，这里的参数包括各层神经元之间的连接权重以及偏置等。
通常是根据实际问题来构造出网络结构，参数的确定则需要神经网络通过训练样本和学习算法来迭代找到最优参数组。
  BP学习算法通常用在最为广泛使用的多层前馈神经网络中。
 
 　　BP算法的主要流程可以总结如下：
　　输入：训练集D=(xk,yk)mk=1; 学习率;
　　过程：
　　1. 在(0, 1)范围内随机初始化网络中所有连接权和阈值
　　2. repeat:
　　3.　　 for all (xk,yk)∈D do
　　4. 　　　　根据当前参数计算当前样本的输出;
　　5. 　　　　计算输出层神经元的梯度项；
　　6. 　　　　计算隐层神经元的梯度项；
　　7. 　　　　更新连接权与阈值
　　8. 　　end for
　　9. until 达到停止条件
　　输出：连接权与阈值确定的多层前馈神经网络
 
神经网络模型
Boltzmann机：标准的Boltzmann机是全连接的，也就是说各层内的神经元都是相互连接的，因此计算复杂度很高，而且难以用来解决实际问题
受限玻尔兹曼机（Restricted Boltzmann Mechine，简称RBM）：层内无连接，层间有连接
　       RBM常常用对比散度（Constrastive Divergence，简称CD）来进行训练。









 
 
 
 
 
 
 
 
 
 
 
