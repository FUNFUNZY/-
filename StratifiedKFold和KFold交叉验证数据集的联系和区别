k折交叉验证就是把数据分为k份，每次取出其中一份作为验证集，剩下的k-1一份作为训练集，重复K次，然后取平均作为误差评估结果。
k越大，学习模型与真实模型越拟合，bias越小，但variance会越大，反之...。




K折交叉切分

为什么要进行交叉验证？
可以用来确定不同类型的模型哪个更好，是一种模型评估的方法。了解：偏差，方差和k-fold交叉验证的关系，

KFold
 class skleaarn.model_selection KFold(n_splits= 'warn', shuffle=False,random_state= None)


StratifiedKFold  分层 K 折交叉验证
  class sklearn.model_selection StratifiedKFold(n_splits= 'warn', shuffle=False,random_state= None)
  

n_splits：将数据集进行 n 等分

shuffle：是否将数据进行洗牌

random_state：随机种子数，保证每次随机的结果都是一样的。一般设置为 0，方便后续调参优化模型。shuffle == True 的时候才有效


sfolder 分出来的训练集和测试集中，0 和 1 的比例都是 1:1，而 kfolder 中并没有这一特性。


关于交叉验证参考：http://blog.sina.com.cn/s/blog_688077cf0100zqpj.html
