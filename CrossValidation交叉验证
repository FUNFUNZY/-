回归问题：

1.train_test_split

缺点：
1.最终模型与参数的选取将极大程度依赖于你对训练集和测试集的划分方法。如果我们的训练集和测试集的划分方法不够好，很有可能无法选择到最好的模型与参数。
2.该方法只用了部分数据进行模型的训练


2. LOOCV（Leave-one-out cross-validation）

用一个数据作为测试集，其他的数据都作为训练集，并将此步骤重复N次（N为数据集的数据数量）。
LOOCV的方法就是每次取出一个数据作为测试集的唯一元素，而其他n-1个数据都作为训练集用于训练模型和调参。
结果就是我们最终训练了n个模型，每次都能得到一个MSE。而计算最终test MSE则就是将这n个MSE取平均。

LOOCV有很多优点。首先它不受测试集合训练集划分方法的影响，因为每一个数据都单独的做过测试集。同时，其用了n-1个数据训练模型，也几乎用到了所有的数据，
保证了模型的bias更小。不过LOOCV的缺点也很明显，那就是计算量过于大，是test set approach耗时的n-1倍。


3.K-fold Cross Validation  K折交叉验证

每次的测试集包含多个数据，具体数目将根据K的选取决定。
比如，K=5，如果K=5，那么我们利用五折交叉验证的步骤就是：
1）.将所有数据集分成5份
2）.不重复地每次取其中一份做测试集，用其他四份做训练集训练模型，之后计算该模型在测试集上的MSE(i)公式
3）.将5次的[公式]取平均得到最后的MSE

*******************************************************************************************************************
K的选取是一个Bias和Variance的trade-off。

K越大，每次投入的训练集的数据越多，模型的Bias越小。但是K越大，又意味着每一次选取的训练集之前的相关性越大（考虑最极端的例子，当k=N，也就是在LOOCV里，每次都训练数据几乎是一样的）。而这种大相关性会导致最终的test error具有更大的Variance。

一般来说，根据经验我们一般选择k=5或10。

*********************************************************************************************************************

分类问题：

参考原文链接：https://zhuanlan.zhihu.com/p/24825503
